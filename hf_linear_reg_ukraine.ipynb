{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f206395a-1287-445f-a7e9-e9c783eb3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc6a199-d638-41a2-8337-6c634f769b14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 14:21:16.891044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-18 14:21:17.503080: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64::/usr/local/opencv-4.5.5/build/lib:/usr/local/opencv-4.5.5/build/lib\n",
      "2024-04-18 14:21:17.503135: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64::/usr/local/opencv-4.5.5/build/lib:/usr/local/opencv-4.5.5/build/lib\n",
      "2024-04-18 14:21:17.503139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at socialmediaie/TRAC2020_ENG_A_bert-base-uncased and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([1, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"socialmediaie/TRAC2020_ENG_A_bert-base-uncased\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"socialmediaie/TRAC2020_ENG_A_bert-base-uncased\", \n",
    "#         num_labels=1, \n",
    "#     ignore_mismatched_sizes=True\n",
    "# ).to(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    './hf_ukraine/run1/checkpoint-65000'\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd627484-75bb-449c-814c-a17acf458f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle        \n",
    "with open('before_war_doc_toxicity_scores.pkl', 'rb') as f:\n",
    "    before_war_doc_scores = pickle.load(f)\n",
    "with open('war_and_after_doc_toxicity_scores.pkl', 'rb') as f:\n",
    "    war_and_after_doc_scores = pickle.load(f)\n",
    "\n",
    "with open('before_war_sample.pkl', 'rb') as f:\n",
    "    before_war_sample = pickle.load(f)\n",
    "with open('war_and_after_sample.pkl', 'rb') as f:\n",
    "    war_and_after_sample = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974e6dae-cb43-4455-9cb2-01b8d0665125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_and_after_shrink = war_and_after_sample.iloc[:800000]\n",
    "war_and_after_doc_scores = war_and_after_doc_scores[:800000]\n",
    "\n",
    "with open('war_and_after_shrink.pkl', 'wb') as f:\n",
    "     pickle.dump(war_and_after_shrink, f)\n",
    "war_and_after_shrink.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef494d5b-0b68-4159-939d-1aa9e573f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = before_war_sample['cleaned_text'].tolist()\n",
    "y_train = before_war_doc_scores\n",
    "x_test = war_and_after_shrink['cleaned_text'].tolist()\n",
    "y_test = war_and_after_doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd201f1-8763-4099-bbd1-6ca8dae1b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train_encodings.pkl', 'rb') as f:\n",
    "    x_train_encodings = pickle.load(f)\n",
    "with open('x_test_encodings.pkl', 'rb') as f:\n",
    "    x_test_encodings = pickle.load(f)\n",
    "\n",
    "# train_encodings_batches[0][\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2d357c-e8d1-4525-b696-da52efb74f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_length = model.config.max_position_embeddings\n",
    "\n",
    "def batch_tokenize(texts, tokenizer, batch_size=32, max_length=None):\n",
    "    # Tokenize all texts at once (adjust if memory constraints are an issue)\n",
    "    encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "    return encodings\n",
    "\n",
    "x_train_encodings = batch_tokenize(x_train, tokenizer, max_length=max_length)\n",
    "x_test_encodings = batch_tokenize(x_test, tokenizer, max_length=max_length)\n",
    "\n",
    "\n",
    "with open('x_train_encodings.pkl', 'wb') as f:\n",
    "     pickle.dump(x_train_encodings, f)\n",
    "with open('x_test_encodings.pkl', 'wb') as f:\n",
    "     pickle.dump(x_test_encodings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63aec00f-d53a-48c6-abf2-3a9c79755142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "max_length = model.config.max_position_embeddings\n",
    "\n",
    "#try not running in batches and just do something like tokenizer xtrain.\n",
    "\n",
    "# def batch_tokenize(texts, tokenizer, batch_size=32, max_length=None):\n",
    "#     # Initialize batch start index\n",
    "#     batch_start = 0\n",
    "#     # Initialize container for batched encodings\n",
    "#     batch_encodings = []\n",
    "    \n",
    "#     # Wrap the range with tqdm for a progress bar\n",
    "#     total_batches = (len(texts) + batch_size - 1) // batch_size  # Compute the total number of batches\n",
    "#     for batch_start in tqdm(range(0, len(texts), batch_size), total=total_batches, desc=\"Tokenizing\"):\n",
    "#         # Calculate batch end index\n",
    "#         batch_end = batch_start + batch_size\n",
    "#         # Slice the texts for the current batch\n",
    "#         batch_texts = texts[batch_start:batch_end]\n",
    "#         # Tokenize the current batch\n",
    "#         encodings = tokenizer(batch_texts, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors = \"pt\")\n",
    "#         # Store the encodings\n",
    "#         batch_encodings.append(encodings)\n",
    "    \n",
    "#     return batch_encodings\n",
    "\n",
    "# # Tokenize data in batches with progress bar\n",
    "# train_encodings_batches = batch_tokenize(x_train[:100], tokenizer, batch_size=32, max_length=max_length)\n",
    "# test_encodings_batches = batch_tokenize(x_test[:100], tokenizer, batch_size=32, max_length=max_length)\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor([self.labels[idx]], dtype=torch.float)  # Ensure labels are correctly shaped\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create dataset\n",
    "# train_dataset = CustomDataset(x_train_encodings, y_train)\n",
    "# test_dataset = CustomDataset(x_test_encodings, y_test)\n",
    "\n",
    "# # #create for batching the data, which is necessary for training the model efficiently. \n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "# with open('train_dataset.pkl', 'wb') as f:\n",
    "#      pickle.dump(train_dataset, f)\n",
    "# with open('test_dataset.pkl', 'wb') as f:\n",
    "#      pickle.dump(test_dataset, f)\n",
    "# with open('train_loader.pkl', 'wb') as f:\n",
    "#      pickle.dump(train_loader, f)\n",
    "# with open('test_loader.pkl', 'wb') as f:\n",
    "#      pickle.dump(test_loader, f)\n",
    "\n",
    "\n",
    "with open('train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open('test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456274a4-be1c-44d6-87f8-1b501721960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 15:56:36.571810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 15:56:37.138157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64::/usr/local/opencv-4.5.5/build/lib:/usr/local/opencv-4.5.5/build/lib\n",
      "2024-04-19 15:56:37.138213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64::/usr/local/opencv-4.5.5/build/lib:/usr/local/opencv-4.5.5/build/lib\n",
      "2024-04-19 15:56:37.138218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55fe92e-db95-4dc0-9e88-6f57ef886470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_encodings2 = tokenizer(x_train, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "# x_test_encodings2 = tokenizer(x_test[:100], truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896e13c-46a0-45c9-af82-f655e3d4df66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i, x in enumerate(x_train_encodings2):\n",
    "    x['labels'] = float(torch.tensor(y_train[i]))\n",
    "\n",
    "for i, x in enumerate(x_test_encodings2):\n",
    "    x['labels'] = float(torch.tensor(y_test[i]))\n",
    "\n",
    "#KEEP FOR LABELS, but maybe ignore other cells above\n",
    "\n",
    "for i, x in enumerate(x_train_encodings):\n",
    "    x['labels'] = float(torch.tensor(y_train[i]))\n",
    "\n",
    "for i, x in enumerate(x_test_encodings):\n",
    "    x['labels'] = float(torch.tensor(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31708d9f-3afd-43f1-a716-6d55f8b6c93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrtcloud-8/miniconda3/envs/hf_38_john/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/linear-regression-with-hugging-face-3883fe729324\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "num_epochs=3\n",
    "\n",
    "#compute the metrics for regression\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}\n",
    "\n",
    "\n",
    "# Specifiy the arguments for the trainer  \n",
    "training_args = TrainingArguments(\n",
    "    fp16=True,\n",
    "    output_dir ='./hf_ukraine/run1',          \n",
    "    num_train_epochs = num_epochs,     \n",
    "    per_device_train_batch_size = 8,  \n",
    "    per_device_eval_batch_size = 8,   \n",
    "    seed=42, \n",
    "    # weight_decay = 0.01,               \n",
    "    # learning_rate = 2e-5,\n",
    "    logging_dir = './logs/run1',            \n",
    "    save_total_limit = 10,\n",
    "    #load_best_model_at_end = True,     \n",
    "    # metric_for_best_model = 'mse',    \n",
    "    evaluation_strategy = \"epoch\",\n",
    "    # save_strategy = \"epoch\",\n",
    ") \n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "\n",
    "\n",
    "# Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,                         \n",
    "    args = training_args,                  \n",
    "    train_dataset = train_dataset,         \n",
    "    eval_dataset = test_dataset, \n",
    "    compute_metrics = compute_metrics_for_regression,     \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86119edf-ac3a-45c3-8ee0-a9807ee96b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65361' max='65361' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65361/65361 5:28:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "      <th>Smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>0.210189</td>\n",
       "      <td>0.116044</td>\n",
       "      <td>-3.617922</td>\n",
       "      <td>112.277100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.019634</td>\n",
       "      <td>0.019634</td>\n",
       "      <td>0.140120</td>\n",
       "      <td>0.084241</td>\n",
       "      <td>-1.052238</td>\n",
       "      <td>113.381690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.017394</td>\n",
       "      <td>0.017394</td>\n",
       "      <td>0.131886</td>\n",
       "      <td>0.080897</td>\n",
       "      <td>-0.818122</td>\n",
       "      <td>115.631120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_139765/2833856379.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=65361, training_loss=0.0010700119822796537, metrics={'train_runtime': 19728.2798, 'train_samples_per_second': 26.504, 'train_steps_per_second': 3.313, 'total_flos': 1.37573220956885e+17, 'train_loss': 0.0010700119822796537, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af55920-87f6-482e-aa4e-743425684321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed8e40a-221b-4c79-8ed3-111222286671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8710/776908323.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100000' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100000/100000 59:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.01722853071987629,\n",
       " 'eval_mse': 0.01722853071987629,\n",
       " 'eval_rmse': 0.13125750422477722,\n",
       " 'eval_mae': 0.08046024292707443,\n",
       " 'eval_r2': -0.8008329840570281,\n",
       " 'eval_smape': 115.61356,\n",
       " 'eval_runtime': 3575.2458,\n",
       " 'eval_samples_per_second': 223.761,\n",
       " 'eval_steps_per_second': 27.97}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the summary\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b775de-c520-485a-8357-9db3614e41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8710/2373867126.py:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = get_cmap('winter')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAIQCAYAAABzIaQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVTklEQVR4nO3deXwNZ///8fdJIgmRxRJiib13Qy2xhtRasYZKa19qS+nGTaneqEp1Uy2llhatrTcppfiqttrUUiqpoLSl9ttObCEhIULm90d+OXXkZGOI8Ho+HufRZuaamc8cZyZ5n7nmGothGIYAAAAAAKZwyO0CAAAAAOBhQsgCAAAAABMRsgAAAADARIQsAAAAADARIQsAAAAATETIAgAAAAATEbIAAAAAwESELAAAAAAwESELAAAAAExEyALyuPnz58tisejIkSO5XQqQK/r27aty5crldhl5woYNG2SxWLRhw4b7ts01a9bI399frq6uslgsunTp0n3bdlbS3o9ly5bd821xrrYvNz6TwP1AyAJuk/aLcNu2bXbnN23aVFWrVr3PVT2Y3nrrLVksFruvmTNn5nZ5Npo2bSqLxaLHHnvM7vyIiAhr7bf/wfXXX3+pU6dOKlu2rFxdXVWqVCm1aNFC06ZNs2lXrly5DN+P1q1b31HdaesMCgqyO//zzz+3biOjz+zrr78ui8Wirl272p1/5MiRDOu2WCz64IMP7qj2B03aZyDtlT9/flWvXl1TpkxRSkqKTdvjx49r3LhxqlevngoVKqSiRYuqadOm+vnnn7O1rbQ/HC0WixYuXGi3zZNPPimLxXLH55Pw8HBNmTLljpa9Xy5cuKAuXboof/78mjFjhv773//Kzc3tnm0v7Zx0/vx5u/OrVq2qpk2b3rPtP6huP8YdHBxUuHBhtWnTRlFRUbldnmmio6NlsVg0efLkdPM6dOggi8WiefPmpZvXuHFjlSpV6n6UiEeIU24XAODuPPfcc+rWrZtcXFxyrYbPPvtMBQsWtJkWEBCQS9VkzNXVVQcPHlR0dLTq1atnM2/RokVydXXVtWvXbKZHRkaqWbNmKlOmjAYMGCAfHx8dP35cv/32mz755BMNHjzYpr2/v7+GDx+ebtslS5a8q7rXr1+vmJgY+fj4ZKvuNIZh6KuvvlK5cuX07bff6vLly3J3d7fbtnv37mrbtm266TVr1rzj2h80pUuX1vjx4yVJ58+fV3h4uF599VWdO3dO7733nrXd//3f/2nChAkKCQlRnz59dOPGDX355Zdq0aKF5s6dq379+mVre66urgoPD1evXr1sph85ckSRkZFydXW9430JDw/Xrl27NHTo0Gwv07hxY129elXOzs53vN2c2Lp1qy5fvqx33nknwy8KHhUPwrk67Ri/efOm9u/fr08//VTNmjXT1q1bVa1atVypyczPZK1atVSgQAH9+uuvevXVV23mRUZGysnJSZs3b7Y5fq9fv66tW7eqffv2d7194FaELCCPc3R0lKOjY67W0KlTJxUtWjRXa8iOihUr6saNG/rqq69sQta1a9e0YsUKBQcH65tvvrFZ5r333pOnp6e2bt0qLy8vm3lnz55Nt41SpUql+4P6bj355JPaunWrlixZoiFDhlinnzhxQps2bdIzzzyTru40GzZs0IkTJ7Ru3Tq1atVKy5cvV58+fey2rVWrlum1P2g8PT1t9vHFF1+Un5+fpk2bprffftt6LDVr1kzHjh2z+Vy/+OKL8vf319ixY7Mdstq2batVq1bp/PnzNusKDw9X8eLF9dhjj+nixYsm7V3Grl27JmdnZzk4ONxVsMuptGPk9mPnbiQkJNzTq2H3qo4H4Vx9+zHeqFEjtWnTRp999pk+/fTTXKnJzM+kk5OTAgICtHnzZpvp+/bt0/nz59WjRw/9+uuvNvO2b9+ua9euqWHDhne9/cTERBUoUOCu14OHA90FgbuU1g1j/vz56eZZLBa99dZbNtM2bNigOnXqyNXVVRUrVtSsWbOsXVxudfXqVf373/9W0aJF5e7urqefflonT55Mt057/fzLlSundu3a6ddff1W9evXk6uqqChUq6Msvv0xX459//qkmTZoof/78Kl26tN59913NmzfPlHsH/vzzT/Xt21cVKlSQq6urfHx81L9/f124cCFd25MnTyo0NFQlS5aUi4uLypcvr5deeknXr1+3trl06ZKGDh0qX19fubi4qFKlSpowYUK6rl6Z6d69u5YsWWKzzLfffqvExER16dIlXftDhw7piSeesPtHYrFixbK93bvh6uqqZ599VuHh4TbTv/rqKxUqVEitWrXKcNlFixapSpUqatasmYKCgrRo0aJ7Xa6k1G+Hx44dq9q1a8vT01Nubm5q1KiR1q9fb9Mu7fiZOHGiZs+erYoVK8rFxUV169bV1q1b06135cqVqlq1qlxdXVW1alWtWLHirup0dXVV3bp1dfnyZZvQ/MQTT6T74sDFxUVt27bViRMndPny5Wytv0OHDnJxcdHSpUttpoeHh6tLly4Z/tG9cOFC1a5dW/nz51fhwoXVrVs3HT9+3Dq/adOm+u6773T06FFrF7C0+9LSuiouXrxYY8aMUalSpVSgQAHFx8dneP/Lli1b1LZtWxUqVEhubm6qXr26PvnkE+v8mJgY9evXT6VLl5aLi4tKlCihDh06ZHqOaNq0qTXQ161bVxaLRX379rXOX7p0qXUfixYtql69eunkyZM26+jbt68KFiyoQ4cOqW3btnJ3d1fPnj0z3KYZkpKS1K5dO3l6eioyMlLSP90Q//77b/Xo0UOFChWy/lGe3fPc3Z6rzTj/3a5Ro0aSUs9zaez9Psqo/m3btqlVq1YqWrSo8ufPr/Lly6t///42yy1evFi1a9eWu7u7PDw8VK1aNZvPlr3P5KZNm9S5c2eVKVNGLi4u8vX11auvvqqrV69muU8NGzbUmTNndPDgQeu0zZs3y8PDQwMHDrQGrlvnpS0npV7FDg4Otv4uqlixot555x3dvHnTZjtptw5s375djRs3VoECBTR69Ogs68OjgytZQAbi4uLs9utPTk6+43Xu2LFDrVu3VokSJTRu3DjdvHlTb7/9try9vdO17du3r77++ms999xzql+/vn755RcFBwdne1sHDx5Up06dFBoaqj59+mju3Lnq27evateurSeeeEJSarBp1qyZLBaLRo0aJTc3N33xxRc57s4SGxtr87Ojo6MKFSqkiIgI/e9//1O/fv3k4+Oj3bt3a/bs2dq9e7d+++036y/yU6dOqV69erp06ZIGDhwoPz8/nTx5UsuWLVNiYqKcnZ2VmJioJk2a6OTJk3rhhRdUpkwZRUZGatSoUTp9+nS2703p0aOH3nrrLW3YsEFPPfWUpNQ/eJs3b243NJUtW1ZRUVHatWtXtu6dSU5Otvu5cXNzU/78+bNVY0Z1t2zZUocOHVLFihWtdXfq1En58uWzu0xSUpK++eYba/fF7t27q1+/fna7HUqp38Laq93Ly0tOTjn7dREfH68vvvhC3bt314ABA3T58mXNmTNHrVq1UnR0tPz9/W3ah4eH6/Lly3rhhRdksVj04Ycf6tlnn9X//vc/6/799NNP6tixo6pUqaLx48frwoUL1j/870Za0MvO1ZaYmBgVKFAg299WFyhQQB06dNBXX32ll156SZL0xx9/aPfu3friiy/0559/plvmvffe05tvvqkuXbro+eef17lz5zRt2jQ1btxYO3bskJeXl9544w3FxcXpxIkT1vtPbu+y+84778jZ2VmvvfaakpKSMuyOFRERoXbt2qlEiRIaMmSIfHx8tGfPHq1evdp65bRjx47avXu3Bg8erHLlyuns2bOKiIjQsWPHMhx05I033tDjjz+u2bNn6+2331b58uWtn9358+erX79+qlu3rsaPH68zZ87ok08+0ebNm637mObGjRtq1aqVGjZsqIkTJ97TKwVXr15Vhw4dtG3bNv3888+qW7euzfzOnTvrscce0/vvvy/DMCQp2+e5jGTnXG3W+e92aYGpUKFCOV727Nmzatmypby9vTVy5Eh5eXnpyJEjWr58ubVNRESEunfvrubNm2vChAmSpD179mjz5s02V+Vvt3TpUiUmJuqll15SkSJFFB0drWnTpunEiRPpvrC4XVpY+vXXX1WpUiVJqUGqfv36CggIUL58+RQZGamnn37aOs/d3V01atSQlPrZLFiwoIYNG6aCBQtq3bp1Gjt2rOLj4/XRRx/ZbOvChQtq06aNunXrpl69eql48eI5fBfxUDMA2Jg3b54hKdPXE088YW1/+PBhQ5Ixb968dOuSZISFhVl/bt++vVGgQAHj5MmT1mkHDhwwnJycjFsPx+3btxuSjKFDh9qsr2/fvunWmVbv4cOHrdPKli1rSDI2btxonXb27FnDxcXFGD58uHXa4MGDDYvFYuzYscM67cKFC0bhwoXTrdOesLAwu+9P2bJlDcMwjMTExHTLfPXVV+lq6927t+Hg4GBs3bo1XfuUlBTDMAzjnXfeMdzc3Iz9+/fbzB85cqTh6OhoHDt2LNNamzRpYv13q1OnjhEaGmoYhmFcvHjRcHZ2NhYsWGCsX7/ekGQsXbrUutxPP/1kODo6Go6OjkaDBg2M119/3fjxxx+N69evp9tG2vtu7zV+/PhM68tI2bJljeDgYOPGjRuGj4+P8c477xiGYRh///23Icn45ZdfrJ+B29+/ZcuWGZKMAwcOGIZhGPHx8Yarq6sxefJkm3Zpn+GMXlFRUTmu+8aNG0ZSUpLNtIsXLxrFixc3+vfvn27bRYoUMWJjY63T/+///s+QZHz77bfWaf7+/kaJEiWMS5cuWaf99NNPNp+5zDRp0sTw8/Mzzp07Z5w7d87Yu3evMWLECEOSERwcnOXyBw4cMFxdXY3nnnsuy7a3fpZWr15tWCwW62d0xIgRRoUKFaw13Xo+OXLkiOHo6Gi89957Nuv766+/DCcnJ5vpwcHBdvc7bdsVKlRIdwymzVu/fr1hGKn/TuXLlzfKli1rXLx40aZt2rF38eJFQ5Lx0UcfZbnft7P32bx+/bpRrFgxo2rVqsbVq1et01evXm1IMsaOHWud1qdPH0OSMXLkyGxtL+2cdO7cObvzn3jiCaNJkybWn2/9d7p8+bLRpEkTo2jRojbnxFvX271793TrzO557m7O1Xd7/ks7zsaNG2ecO3fOiImJMTZt2mTUrVs33TkvbV9vd3v9K1assHveudWQIUMMDw8P48aNGxm2uf0zaRj239Px48cbFovFOHr0aKb7Gh8fbzg6OlrP8YZhGI8//rgxbtw4wzAMo169esaIESOs87y9vY0WLVpkuu0XXnjBKFCggHHt2jXrtCZNmhiSjJkzZ2ZaDx5ddBcEMjBjxgxFRESke1WvXv2O1nfz5k39/PPPCgkJsRkEoVKlSmrTpo1N2zVr1kiSXn75ZZvptw+ykJkqVapYu4JIkre3tx5//HH973//s9lOgwYNbK4qFC5cOMfdcb755hub9yitS9qtV26uXbum8+fPq379+pKk33//XZKUkpKilStXqn379qpTp066dad9C7x06VI1atRIhQoV0vnz562voKAg3bx5Uxs3bsx2vT169NDy5ct1/fp1LVu2TI6OjnrmmWfstm3RooWioqL09NNP648//tCHH36oVq1aqVSpUlq1alW69gEBAXY/N927d892ffY4OjqqS5cu+uqrrySldgP09fW1+Te+3aJFi1SnTh3rt7nu7u4KDg7OsMvgwIED7dZepUqVO6o37cpJSkqKYmNjdePGDdWpU8f6b3+rrl272nybnrZfaZ/X06dPa+fOnerTp488PT2t7Vq0aJGj+vbu3Stvb295e3vLz89PH330kZ5++mm73X1vlZiYqM6dOyt//vw5Hm2xZcuWKly4sBYvXizDMLR48eIMPw/Lly9XSkqKunTpYvM59/Hx0WOPPZauu2Vm+vTpk+XV0x07dujw4cMaOnRouit5acde/vz55ezsrA0bNphy/9i2bdt09uxZvfzyyzb34gQHB8vPz0/fffddumXSrgLeK3FxcWrZsqX27t2rDRs2pLvSmubFF19MNy0757nMZOdcbdb5LywsTN7e3vLx8VGjRo20Z88eTZo0SZ06dcrW8rdK+7ysXr06wx4eXl5eSkhIUERERI7Wfet7mpCQoPPnzyswMFCGYWjHjh2ZLuvu7q7q1atb7706f/689u3bp8DAQEmp97imdRHcv3+/zp07Z3M/1q3bvnz5ss6fP69GjRopMTFRe/futdmWi4tLtu/PxKOH7oJABurVq2f3j/60X3I5dfbsWV29etX6B++tbp929OhROTg4qHz58pm2y0yZMmXSTStUqJDNH0lHjx5VgwYNsqwnK40bN7Y78EVsbKzGjRunxYsXpxskIi4uTpJ07tw5xcfHZ9kV78CBA/rzzz/tdq2U7A9CkZFu3brptdde0w8//KBFixapXbt2GY64J6XeT5IWyv744w+tWLFCkydPVqdOnbRz506bP/KLFi16z0ZR69Gjh6ZOnao//vhD4eHh6tatW4ZdkS5duqTvv/9egwYNsrk34cknn9Q333yj/fv361//+pfNMo899piptS9YsECTJk3S3r17bf4Iu/1zLaX/vKYFrrTP69GjR6013u7xxx/P1h+zUuo9MJ9//rlSUlJ06NAhvffeezp37lymN97fvHlT3bp1099//60ffvghxyNF5suXT507d1Z4eLjq1aun48ePq0ePHnbbHjhwQIZhZPiogYy6htpj732+Xdq9OJkdfy4uLpowYYKGDx+u4sWLq379+mrXrp169+5tt9tpVtL+LR9//PF08/z8/NINTODk5HTXXUJvZe+YGTp0qK5du6YdO3ZYu+jZY+89zc55LjPZOVdn9/x37tw5m3uHChYsaNONdODAgercubOuXbumdevWaerUqenuNcquJk2aqGPHjho3bpwmT56spk2bKiQkRD169LB2OX/55Zf19ddfq02bNipVqpRatmypLl26ZPlIi2PHjmns2LFatWpVumCfnfe0YcOGmjZtms6fP6/IyEg5Ojpag29gYKA+/fRTJSUlpbsfS5J2796tMWPGaN26dYqPj89026VKlbpvI3Ui7yFkAXcpoz9y7/QXl1kyuqHe+P/3EdwPXbp0UWRkpEaMGCF/f38VLFhQKSkpat26dY5v1k5JSVGLFi30+uuv251/e2DITIkSJdS0aVNNmjRJmzdvznBkvts5Ozurbt26qlu3rv71r3+pX79+Wrp0qcLCwrK97bsREBCgihUraujQoTp8+HCGf6hLqd98JyUladKkSZo0aVK6+YsWLdK4cePuWa0LFy5U3759FRISohEjRqhYsWJydHTU+PHjbW6yT3O/Pq9ubm42QfLJJ59UrVq1NHr0aE2dOtXuMgMGDNDq1au1aNEi6318OdWjRw/NnDlTb731lmrUqJHh1beUlBRZLBb98MMPdt+T2++7yszd3AN4u6FDh6p9+/ZauXKlfvzxR7355psaP3681q1bd8+H+HdxcZGDQ/Y63qSF5YwGSEhMTLQbqDt06KDFixfrgw8+0Jdffpnh9uy9p3d7nsvOZz+757+6detaQ6yUeuXq1oGSbv0ipV27dnJ0dNTIkSPVrFkz65eK2f2dlvZMwd9++03ffvutfvzxR/Xv31+TJk3Sb7/9poIFC6pYsWLauXOnfvzxR/3www/64YcfNG/ePPXu3VsLFizIcDstWrRQbGys/vOf/8jPz09ubm46efKk+vbtm633NC1kbd68WZGRkapWrZr12AkMDFRSUpK2bt2qX3/9VU5OTtYAdunSJTVp0kQeHh56++23VbFiRbm6uur333/Xf/7zn3TbNvMYw8OHkAXcpbRv3C9dumQz/dZfdFLqSHRpz2m63e3TypYtq5SUFB0+fNjmG217y96NsmXLZqueO3Hx4kWtXbtW48aN09ixY63TDxw4YNPO29tbHh4e2rVrV6brq1ixoq5cuWLalZYePXro+eefl5eXl91nQ2Ul7Q+S06dPm1JPdnXv3l3vvvuuKleunGGXJik1RFWtWtVuAJw1a5bCw8PvachatmyZKlSooOXLl9v80XangbRs2bKS0n9+pNThme9U9erV1atXL82aNUuvvfZauqsKI0aM0Lx58zRlypS76vLZsGFDlSlTRhs2bLAOAGBPxYoVZRiGypcvn+UXB1kNqJAdaQNR7Nq1K8tjq2LFiho+fLiGDx+uAwcOyN/fX5MmTcrwYcsZSfu33LdvX7rQum/fPuv8O3Hrun19fW3mJSYm6vjx42rZsmW65UJCQtSyZUv17dtX7u7u+uyzz7K1veye5+5Wds9/ixYtsgmYFSpUyLT9G2+8oc8//1xjxoyxdlO/9XfarV1Ib/+dlqZ+/fqqX7++3nvvPYWHh6tnz55avHixnn/+eUmpX061b99e7du3V0pKil5++WXNmjVLb775pt1eE3/99Zf279+vBQsWqHfv3tbpOelyeOvgF1FRUXryySet80qWLKmyZctq8+bN2rx5s2rWrGkdTGXDhg26cOGCli9frsaNG1uXOXz4cLa3DaThnizgLnl4eKho0aLp+sTf/swRR0dHBQUFaeXKlTp16pR1+sGDB/XDDz/YtE0bkvv2dUybNs3M0tWqVStFRUVp586d1mmxsbGmDPOd9u3s7Vcibh8Fy8HBQSEhIfr222+1bdu2dOtJW75Lly6KiorSjz/+mK7NpUuXdOPGjRzV16lTJ4WFhenTTz/NtLvH+vXr7V5N+f777yXZ7/J0Lz3//PMKCwuze3UqzfHjx7Vx40Z16dJFnTp1Svfq16+fDh48qC1bttyzOu39+2/ZskVRUVF3tL4SJUrI399fCxYssOmyExERob///vuuan399deVnJysjz/+2Gb6Rx99pIkTJ2r06NGZjoSWHRaLRVOnTlVYWJiee+65DNs9++yzcnR01Lhx49J97gzDsBkW3M3NLVtdpzJTq1YtlS9fXlOmTEn3RVHa9hMTE9M97LpixYpyd3dXUlJSjrdZp04dFStWTDNnzrRZ/ocfftCePXtyNIrq7Zo3by5nZ2d99tln6a46zJ49Wzdu3Eh3D2ya3r17a+rUqZo5c6b+85//ZGt72T3P3a3snv+efPJJBQUFWV9ZhSwvLy+98MIL+vHHH62/B9KC962/0xISEtJdebp48WK6/U774ift3/X2YewdHBys9zVn9Nmx954ahmEz7HtWSpYsqfLly2vt2rXatm2b9X6sNIGBgVq5cqX27dtn01XQ3ravX7+ea88QQ97GlSzABM8//7w++OADPf/886pTp442btyo/fv3p2v31ltv6aefftKTTz6pl156STdv3tT06dNVtWpVm6BTu3ZtdezYUVOmTNGFCxesQ7inrdOMb7Cl1D8uFy5cqBYtWmjw4MHWIdzLlCmj2NjYu9qOh4eHGjdurA8//FDJyckqVaqUfvrpJ7vfCL7//vv66aef1KRJEw0cOFCVK1fW6dOntXTpUv3666/y8vLSiBEjtGrVKrVr1846vHFCQoL++usvLVu2TEeOHMnRA5E9PT3TPcPMnsGDBysxMVHPPPOM/Pz8dP36dUVGRmrJkiUqV65cupueT548afeb/YIFCyokJERS6rDJ5cuXV58+fbIccOF2ZcuWzbLu8PBwGYZhHaL4dm3btpWTk5MWLVqkgIAA6/Tff//dbu0VK1a03ruXNvT2vHnzbJ55dLt27dpp+fLleuaZZxQcHKzDhw9r5syZqlKliq5cuZL1jtoxfvx4BQcHq2HDhurfv79iY2M1bdo0PfHEE3e8Til14IG2bdvqiy++0JtvvqkiRYpoxYoVev311/XYY4+pcuXK6d6XFi1a5Hi45g4dOqhDhw6ZtqlYsaLeffddjRo1SkeOHFFISIjc3d11+PBhrVixQgMHDtRrr70mKfU8sWTJEg0bNkx169ZVwYIF1b59+xzV5ODgoM8++0zt27eXv7+/+vXrpxIlSmjv3r3avXu3fvzxR+3fv1/NmzdXly5dVKVKFTk5OWnFihU6c+aMunXrlqPtSan3lU2YMEH9+vVTkyZN1L17d+sQ7uXKldOrr76a43WmKVasmMaOHasxY8aocePGevrpp1WgQAFFRkbqq6++UsuWLTN9jwYNGqT4+Hi98cYb8vT0zPK5Rzk5z90Ns89/txoyZIimTJmiDz74QIsXL1bLli1VpkwZhYaGasSIEXJ0dNTcuXPl7e2tY8eOWZdbsGCBPv30Uz3zzDOqWLGiLl++rM8//1weHh7W3gHPP/+8YmNj9dRTT6l06dI6evSopk2bJn9/f1WuXNluPX5+fqpYsaJee+01nTx5Uh4eHvrmm29yPOhKw4YN9d///leSbK5kSakhK20QoVtDVmBgoAoVKqQ+ffro3//+tywWi/773//e1272eIjc17EMgTwgo+Gw09w+5LJhpA75Ghoaanh6ehru7u5Gly5djLNnz6Ybbt0wDGPt2rVGzZo1DWdnZ6NixYrGF198YQwfPtxwdXW1aZeQkGC88sorRuHChY2CBQsaISEhxr59+wxJxgcffJCu3tuHBbY3JHWTJk1shi82DMPYsWOH0ahRI8PFxcUoXbq0MX78eGPq1KmGJCMmJibT9yqr4ZJPnDhhPPPMM4aXl5fh6elpdO7c2Th16pTd9+Xo0aNG7969DW9vb8PFxcWoUKGC8corr9gMA3758mVj1KhRRqVKlQxnZ2ejaNGiRmBgoDFx4kS7Q6rfvu+3/7vdzt4Q7j/88IPRv39/w8/PzyhYsKDh7OxsVKpUyRg8eLBx5swZm+UzG8L91qG2//rrr2wPS53Rv+Wtbv/MVqtWzShTpkymyzRt2tQoVqyYkZycnOUQ7n369LEuN23aNEOSsWbNmkzXn5KSYrz//vtG2bJlDRcXF6NmzZrG6tWrjT59+ti8F2nbtjc8uL3PyTfffGNUrlzZcHFxMapUqWIsX7483TozktlnYMOGDTbby+jxBGmvW4ebtsfeZyknNX3zzTdGw4YNDTc3N8PNzc3w8/MzXnnlFWPfvn3WNleuXDF69OhheHl52XzGMtu2veGyDcMwfv31V6NFixaGu7u74ebmZlSvXt2YNm2aYRiGcf78eeOVV14x/Pz8DDc3N8PT09MICAgwvv7660z3zTAyP58uWbLEqFmzpuHi4mIULlzY6Nmzp3HixAmbNn369DHc3Nyy3M7tFi5caNSvX99wc3MzXFxcDD8/P2PcuHE2Q3AbRsbv1euvv25IMqZPn24YRubnuuye5+72XH0357/MjjPDSH08iKOjo3Hw4EHDMFIfIxIQEGA4OzsbZcqUMT7++ON09f/+++9G9+7djTJlyhguLi5GsWLFjHbt2hnbtm2zrnfZsmVGy5YtjWLFilnX9cILLxinT5+2trH3mfz777+NoKAgo2DBgkbRokWNAQMGGH/88YehDB6XYs+sWbMMSUapUqXSzfv999+tx/Lt5/HNmzcb9evXN/Lnz2+ULFnS+tiO22vMzu8UPNoshkE8B3JbSEiIdu/enWU//p07d6pmzZpauHBhjodZz4mhQ4dq1qxZunLlSoY3ZePOffrpp3r99dd16NChPPfwyi5duujIkSOKjo7O7VIAAHhgcU8WcJ/dPurVgQMH9P3336tp06aZtpNS+/k7ODjY3JBrdj0XLlzQf//7XzVs2JCAdY+sX79e//73v/NcwDIMQxs2bNC7776b26UAAPBA40oWcJ+VKFFCffv2VYUKFXT06FF99tlnSkpK0o4dO2xGEhw3bpy2b9+uZs2aycnJyTr87cCBAzVr1izT6vH391fTpk1VuXJlnTlzRnPmzNGpU6e0du1aU8McAADAo4KQBdxn/fr10/r16xUTEyMXFxc1aNBA77//vmrVqmXTLiIiQuPGjdPff/+tK1euqEyZMnruuef0xhtvyMnJvDFrRo8erWXLlunEiROyWCyqVauWwsLC7tkDdQEAAB52hCwAAAAAMBH3ZAEAAACAiQhZAAAAAGAiHkachZSUFJ06dUru7u6mPQAWAAAAQN5jGIYuX76skiVLysEh4+tVhKwsnDp1Sr6+vrldBgAAAIAHxPHjx1W6dOkM5xOysuDu7i4p9Y308PDI5WoAAAAA5Jb4+Hj5+vpaM0JGCFlZSOsi6OHhQcgCAAAAkOVtRAx8AQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYA4KEzY8YMlStXTq6urgoICFB0dHSm7ZcuXSo/Pz+5urqqWrVq+v77723mX7lyRYMGDVLp0qWVP39+ValSRTNnzrRpc+3aNb3yyisqUqSIChYsqI4dO+rMmTM2bSwWS7rX4sWLzdlpAMADg5AFAHioLFmyRMOGDVNYWJh+//131ahRQ61atdLZs2ftto+MjFT37t0VGhqqHTt2KCQkRCEhIdq1a5e1zbBhw7RmzRotXLhQe/bs0dChQzVo0CCtWrXK2ubVV1/Vt99+q6VLl+qXX37RqVOn9Oyzz6bb3rx583T69GnrKyQkxPT3AACQuyyGYRi5XcSDLD4+Xp6enoqLi5OHh0dulwMAyEJAQIDq1q2r6dOnS5JSUlLk6+urwYMHa+TIkenad+3aVQkJCVq9erV1Wv369eXv72+9WlW1alV17dpVb775prVN7dq11aZNG7377ruKi4uTt7e3wsPD1alTJ0nS3r17VblyZUVFRal+/fqSUq9krVixgmAFAHlUdrMBV7IAAA+N69eva/v27QoKCrJOc3BwUFBQkKKiouwuExUVZdNeklq1amXTPjAwUKtWrdLJkydlGIbWr1+v/fv3q2XLlpKk7du3Kzk52WY9fn5+KlOmTLrtvvLKKypatKjq1aunuXPniu86AeDh45TbBQAAYJbz58/r5s2bKl68uM304sWLa+/evXaXiYmJsds+JibG+vO0adM0cOBAlS5dWk5OTnJwcNDnn3+uxo0bW9fh7OwsLy+vTNfz9ttv66mnnlKBAgX0008/6eWXX9aVK1f073//+252GwDwgCFkAQCQhWnTpum3337TqlWrVLZsWW3cuFGvvPKKSpYsme4qWGZu7W5Ys2ZNJSQk6KOPPiJkAcBDhu6CAICHRtGiReXo6JhuVL8zZ87Ix8fH7jI+Pj6Ztr969apGjx6tjz/+WO3bt1f16tU1aNAgde3aVRMnTrSu4/r167p06VK2tyul3j924sQJJSUl5XRXAQAPMEIWAOCh4ezsrNq1a2vt2rXWaSkpKVq7dq0aNGhgd5kGDRrYtJekiIgIa/vk5GQlJyfLwcH2V6ajo6NSUlIkpQ6CkS9fPpv17Nu3T8eOHctwu5K0c+dOFSpUSC4uLjnbUQDAA43uggCAh8qwYcPUp08f1alTR/Xq1dOUKVOUkJCgfv36SZJ69+6tUqVKafz48ZKkIUOGqEmTJpo0aZKCg4O1ePFibdu2TbNnz5YkeXh4qEmTJhoxYoTy58+vsmXL6pdfftGXX36pjz/+WJLk6emp0NBQDRs2TIULF5aHh4cGDx6sBg0aWEcW/Pbbb3XmzBnVr19frq6uioiI0Pvvv6/XXnstF94lAMC9RMgCADxUunbtqnPnzmns2LGKiYmRv7+/1qxZYx3c4tixYzZXpQIDAxUeHq4xY8Zo9OjReuyxx7Ry5UpVrVrV2mbx4sUaNWqUevbsqdjYWJUtW1bvvfeeXnzxRWubyZMny8HBQR07dlRSUpJatWqlTz/91Do/X758mjFjhl599VUZhqFKlSrp448/1oABA+7DuwIAuJ94TlYWeE4WAAAAAInnZAEAAABAriBkAQAAAICJuCcLAB5QlnEbcrsE4IFmhDXN7RIAwC6uZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJCFR8qMGTNUrlw5ubq6KiAgQNHR0Zm2X7p0qfz8/OTq6qpq1arp+++/t5m/fPlytWzZUkWKFJHFYtHOnTtt5h85ckQWi8Xua+nSpZKkP/74Q927d5evr6/y58+vypUr65NPPjF1vwEAAHD/ELLwyFiyZImGDRumsLAw/f7776pRo4ZatWqls2fP2m0fGRmp7t27KzQ0VDt27FBISIhCQkK0a9cua5uEhAQ1bNhQEyZMsLsOX19fnT592uY1btw4FSxYUG3atJEkbd++XcWKFdPChQu1e/duvfHGGxo1apSmT59u/psAAACAe85iGIaR20U8yOLj4+Xp6am4uDh5eHjkdjm4CwEBAapbt641vKSkpMjX11eDBw/WyJEj07Xv2rWrEhIStHr1auu0+vXry9/fXzNnzrRpe+TIEZUvX147duyQv79/pnXUrFlTtWrV0pw5czJs88orr2jPnj1at25dDvYQDxvLuA25XQLwQDPCmuZ2CQAeMdnNBlzJwiPh+vXr2r59u4KCgqzTHBwcFBQUpKioKLvLREVF2bSXpFatWmXYPju2b9+unTt3KjQ0NNN2cXFxKly48B1vBwAAALnHKbcLAO6H8+fP6+bNmypevLjN9OLFi2vv3r12l4mJibHbPiYm5o7rmDNnjipXrqzAwMAM20RGRmrJkiX67rvv7ng7AAAAyD1cyQLuk6tXryo8PDzTq1i7du1Shw4dFBYWppYtW97H6gAAAGAWQhYeCUWLFpWjo6POnDljM/3MmTPy8fGxu4yPj0+O2mdl2bJlSkxMVO/eve3O//vvv9W8eXMNHDhQY8aMuaNtAAAAIPcRsvBIcHZ2Vu3atbV27VrrtJSUFK1du1YNGjSwu0yDBg1s2ktSREREhu2zMmfOHD399NPy9vZON2/37t1q1qyZ+vTpo/fee++O1g8AAIAHA/dk4ZExbNgw9enTR3Xq1FG9evU0ZcoUJSQkqF+/fpKk3r17q1SpUho/frwkaciQIWrSpIkmTZqk4OBgLV68WNu2bdPs2bOt64yNjdWxY8d06tQpSdK+ffskpV4Fu/WK18GDB7Vx48Z0z9mSUrsIPvXUU2rVqpWGDRtmvefL0dHRbiADAADAg40rWXhkdO3aVRMnTtTYsWPl7++vnTt3as2aNdbBLY4dO6bTp09b2wcGBio8PFyzZ89WjRo1tGzZMq1cuVJVq1a1tlm1apVq1qyp4OBgSVK3bt1Us2bNdEO8z507V6VLl7Z7n9WyZct07tw5LVy4UCVKlLC+6tatey/eBgAAANxjPCcrCzwnC0Bu4TlZQOZ4ThaA+43nZAEAAABALiBkAQAAAICJGPgij7FYcrsC4MFGB2gAAJDbuJIFAAAAACbKcyFrxowZKleunFxdXRUQEKDo6OhM2y9dulR+fn5ydXVVtWrV7A6hDQAAAABmyVMha8mSJRo2bJjCwsL0+++/q0aNGmrVqpXOnj1rt31kZKS6d++u0NBQ7dixQyEhIQoJCdGuXbvuc+UAAAAAHhV5agj3gIAA1a1bV9OnT5ckpaSkyNfXV4MHD9bIkSPTte/atasSEhK0evVq67T69evL398/3XOMMvKgDeHOPVlA5vLOGS1rDOEOZI4h3AHcbw/dEO7Xr1/X9u3bFRQUZJ3m4OCgoKAgRUVF2V0mKirKpr0ktWrVKsP2AAAAAHC38szogufPn9fNmzdVvHhxm+nFixfX3r177S4TExNjt31MTEyG20lKSlJSUpL15/j4+LuoGgAAAMCjJs+ErPtl/PjxGjduXG6XkaGHqSsUgMzRFQp4NFj04P7dATwoDIXldgk5kme6CxYtWlSOjo46c+aMzfQzZ87Ix8fH7jI+Pj45ai9Jo0aNUlxcnPV1/Pjxuy8eAAAAwCMjz4QsZ2dn1a5dW2vXrrVOS0lJ0dq1a9WgQQO7yzRo0MCmvSRFRERk2F6SXFxc5OHhYfMCAAAAgOzKU90Fhw0bpj59+qhOnTqqV6+epkyZooSEBPXr10+S1Lt3b5UqVUrjx4+XJA0ZMkRNmjTRpEmTFBwcrMWLF2vbtm2aPXt2bu4GAAAAgIdYngpZXbt21blz5zR27FjFxMTI399fa9assQ5ucezYMTk4/HNxLjAwUOHh4RozZoxGjx6txx57TCtXrlTVqlVzaxcAAAAAPOTy1HOycsOD9pwsAADwcGHgCyBrD8rAFw/dc7IAAAAAIC8gZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJgoz4Ss2NhY9ezZUx4eHvLy8lJoaKiuXLmSafvBgwfr8ccfV/78+VWmTBn9+9//Vlxc3H2sGgAAAMCjJs+ErJ49e2r37t2KiIjQ6tWrtXHjRg0cODDD9qdOndKpU6c0ceJE7dq1S/Pnz9eaNWsUGhp6H6sGAAAA8KixGIZh5HYRWdmzZ4+qVKmirVu3qk6dOpKkNWvWqG3btjpx4oRKliyZrfUsXbpUvXr1UkJCgpycnLK1THx8vDw9PRUXFycPD4873gcAAAB7LBqX2yUADzxDYbldgqTsZ4M8cSUrKipKXl5e1oAlSUFBQXJwcNCWLVuyvZ60NyOzgJWUlKT4+HibFwAAAABkV54IWTExMSpWrJjNNCcnJxUuXFgxMTHZWsf58+f1zjvvZNrFUJLGjx8vT09P68vX1/eO6wYAAADw6MnVkDVy5EhZLJZMX3v37r3r7cTHxys4OFhVqlTRW2+9lWnbUaNGKS4uzvo6fvz4XW8fAAAAwKMjezcm3SPDhw9X3759M21ToUIF+fj46OzZszbTb9y4odjYWPn4+GS6/OXLl9W6dWu5u7trxYoVypcvX6btXVxc5OLikq36AQAAAOB2uRqyvL295e3tnWW7Bg0a6NKlS9q+fbtq164tSVq3bp1SUlIUEBCQ4XLx8fFq1aqVXFxctGrVKrm6uppWOwAAAADYkyfuyapcubJat26tAQMGKDo6Wps3b9agQYPUrVs368iCJ0+elJ+fn6KjoyWlBqyWLVsqISFBc+bMUXx8vGJiYhQTE6ObN2/m5u4AAAAAeIjl6pWsnFi0aJEGDRqk5s2by8HBQR07dtTUqVOt85OTk7Vv3z4lJiZKkn7//XfryIOVKlWyWdfhw4dVrly5+1Y7AAAAgEdHnnhOVm7iOVkAAOBe4jlZQNZ4ThYAAAAAPMIIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYKMch6/jx4zpx4oT15+joaA0dOlSzZ882tTAAAAAAyItyHLJ69Oih9evXS5JiYmLUokULRUdH64033tDbb79teoEAAAAAkJfkOGTt2rVL9erVkyR9/fXXqlq1qiIjI7Vo0SLNnz/f7PoAAAAAIE/JcchKTk6Wi4uLJOnnn3/W008/LUny8/PT6dOnza0OAAAAAPKYHIesJ554QjNnztSmTZsUERGh1q1bS5JOnTqlIkWKmF4gAAAAAOQlOQ5ZEyZM0KxZs9S0aVN1795dNWrUkCStWrXK2o0QAAAAAB5VTjldoGnTpjp//rzi4+NVqFAh6/SBAweqQIECphYHAAAAAHnNHT0nyzAMbd++XbNmzdLly5clSc7OzoQsAAAAAI+8HF/JOnr0qFq3bq1jx44pKSlJLVq0kLu7uyZMmKCkpCTNnDnzXtQJAAAAAHlCjq9kDRkyRHXq1NHFixeVP39+6/RnnnlGa9euNbU4AAAAAMhrcnwla9OmTYqMjJSzs7PN9HLlyunkyZOmFQYAAAAAeVGOr2SlpKTo5s2b6aafOHFC7u7uphQFAAAAAHlVjkNWy5YtNWXKFOvPFotFV65cUVhYmNq2bWtmbTZiY2PVs2dPeXh4yMvLS6Ghobpy5Uq2ljUMQ23atJHFYtHKlSvvWY0AAAAAkOOQNWnSJG3evFlVqlTRtWvX1KNHD2tXwQkTJtyLGiVJPXv21O7duxUREaHVq1dr48aNGjhwYLaWnTJliiwWyz2rDQAAAADS5PierNKlS+uPP/7Q4sWL9eeff+rKlSsKDQ1Vz549bQbCMNOePXu0Zs0abd26VXXq1JEkTZs2TW3bttXEiRNVsmTJDJfduXOnJk2apG3btqlEiRL3pD4AAAAASJPjkCVJTk5O6tWrl9m1ZCgqKkpeXl7WgCVJQUFBcnBw0JYtW/TMM8/YXS4xMVE9evTQjBkz5OPjk61tJSUlKSkpyfpzfHz83RUPAAAA4JGS45D15ZdfZjq/d+/ed1xMRmJiYlSsWDGbaU5OTipcuLBiYmIyXO7VV19VYGCgOnTokO1tjR8/XuPGjbvjWgEAAAA82nIcsoYMGWLzc3JyshITE+Xs7KwCBQrkKGSNHDkyy/u49uzZk9MSJUmrVq3SunXrtGPHjhwtN2rUKA0bNsz6c3x8vHx9fe+oBgAAAACPnhyHrIsXL6abduDAAb300ksaMWJEjtY1fPhw9e3bN9M2FSpUkI+Pj86ePWsz/caNG4qNjc2wG+C6det06NAheXl52Uzv2LGjGjVqpA0bNthdzsXFRS4uLtndBQAAAACwYTEMwzBjRdu2bVOvXr20d+9eM1ZnY8+ePapSpYq2bdum2rVrS5J++ukntW7dWidOnLA78EVMTIzOnz9vM61atWr65JNP1L59e5UvXz5b246Pj5enp6fi4uLk4eFx9zsDAABwC4u4TQHIiqGw3C5BUvazwR0NfGF3RU5OOnXqlFmrs1G5cmW1bt1aAwYM0MyZM5WcnKxBgwapW7du1oB18uRJNW/eXF9++aXq1asnHx8fu1e5ypQpk+2ABQAAAAA5leOQtWrVKpufDcPQ6dOnNX36dD355JOmFXa7RYsWadCgQWrevLkcHBzUsWNHTZ061To/OTlZ+/btU2Ji4j2rAQAAAACykuOQFRISYvOzxWKRt7e3nnrqKU2aNMmsutIpXLiwwsPDM5xfrlw5ZdXz0aSekQAAAACQoRyHrJSUlHtRBwAAAAA8FBxyuwAAAAAAeJhk60rWrc+NysrHH398x8UAAAAAQF6XrZCV3Qf6WiyWuyoGAAAAAPK6bIWs9evX3+s6AAAAAOChwD1ZAAAAAGCiO3oY8bZt2/T111/r2LFjun79us285cuXm1IYAAAAAORFOb6StXjxYgUGBmrPnj1asWKFkpOTtXv3bq1bt06enp73okYAAAAAyDNyHLLef/99TZ48Wd9++62cnZ31ySefaO/everSpYvKlClzL2oEAAAAgDwjxyHr0KFDCg4OliQ5OzsrISFBFotFr776qmbPnm16gQAAAACQl+Q4ZBUqVEiXL1+WJJUqVUq7du2SJF26dEmJiYnmVgcAAAAAeUy2Q1ZamGrcuLEiIiIkSZ07d9aQIUM0YMAAde/eXc2bN783VQIAAABAHpHt0QWrV6+uunXrKiQkRJ07d5YkvfHGG8qXL58iIyPVsWNHjRkz5p4VCgAAAAB5gcUwDCM7DTdt2qR58+Zp2bJlSklJUceOHfX888+rUaNG97rGXBUfHy9PT0/FxcXJw8Mjt8sBAAAPGYvG5XYJwAPPUFhulyAp+9kg290FGzVqpLlz5+r06dOaNm2ajhw5oiZNmuhf//qXJkyYoJiYGFMKBwAAAIC8LMcDX7i5ualfv3765ZdftH//fnXu3FkzZsxQmTJl9PTTT9+LGgEAAAAgz8hxyLpVpUqVNHr0aI0ZM0bu7u767rvvzKoLAAAAAPKkbA98cbuNGzdq7ty5+uabb+Tg4KAuXbooNDTUzNoAAAAAIM/JUcg6deqU5s+fr/nz5+vgwYMKDAzU1KlT1aVLF7m5ud2rGgEAAAAgz8h2yGrTpo1+/vlnFS1aVL1791b//v31+OOP38vaAAAAACDPyXbIypcvn5YtW6Z27drJ0dHxXtYEAAAAAHlWtkPWqlWr7mUdAAAAAPBQuKvRBQEAAAAAtghZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJ8kzIio2NVc+ePeXh4SEvLy+FhobqypUrWS4XFRWlp556Sm5ubvLw8FDjxo119erV+1AxAAAAgEdRnglZPXv21O7duxUREaHVq1dr48aNGjhwYKbLREVFqXXr1mrZsqWio6O1detWDRo0SA4OeWa3AQAAAOQxFsMwjNwuIit79uxRlSpVtHXrVtWpU0eStGbNGrVt21YnTpxQyZIl7S5Xv359tWjRQu+8884dbzs+Pl6enp6Ki4uTh4fHHa8HAADAHovG5XYJwAPPUFhulyAp+9kgT1zSiYqKkpeXlzVgSVJQUJAcHBy0ZcsWu8ucPXtWW7ZsUbFixRQYGKjixYurSZMm+vXXX+9X2QAAAAAeQXkiZMXExKhYsWI205ycnFS4cGHFxMTYXeZ///ufJOmtt97SgAEDtGbNGtWqVUvNmzfXgQMHMtxWUlKS4uPjbV4AAAAAkF25GrJGjhwpi8WS6Wvv3r13tO6UlBRJ0gsvvKB+/fqpZs2amjx5sh5//HHNnTs3w+XGjx8vT09P68vX1/eOtg8AAADg0eSUmxsfPny4+vbtm2mbChUqyMfHR2fPnrWZfuPGDcXGxsrHx8fuciVKlJAkValSxWZ65cqVdezYsQy3N2rUKA0bNsz6c3x8PEELAAAAQLblasjy9vaWt7d3lu0aNGigS5cuafv27apdu7Ykad26dUpJSVFAQIDdZcqVK6eSJUtq3759NtP379+vNm3aZLgtFxcXubi45GAvAAAAAOAfeeKerMqVK6t169YaMGCAoqOjtXnzZg0aNEjdunWzjix48uRJ+fn5KTo6WpJksVg0YsQITZ06VcuWLdPBgwf15ptvau/evQoNDc3N3QEAAADwEMvVK1k5sWjRIg0aNEjNmzeXg4ODOnbsqKlTp1rnJycna9++fUpMTLROGzp0qK5du6ZXX31VsbGxqlGjhiIiIlSxYsXc2AUAAAAAj4A88Zys3MRzsgAAwL3Ec7KArPGcLAAAAAB4hBGyAAAAAMBEhCwAAAAAMBEhCwAAAABMRMgCAAAAABMRsgAAAADARIQsAAAAADARIQsAAAAATETIAgAAAAATEbIAAAAAwESELAAAAAAwESELAAAAAExEyAIAAAAAExGyAAAAAMBEhCwAAAAAMBEhCwAAAABMRMgCAAAAABMRsgAAAADARIQsAAAAADARIQsAAAAATETIAgAAAAATEbIAAAAAwESELAAAAAAwESELAAAAAExEyAIAAAAAExGyAAAAAMBEhCwAAAAAMBEhCwAAAABMRMgCAAAAABMRsgAAAADARIQsAAAAADARIQsAAAAATETIAgAAAAATEbIAAAAAwESELAAAAAAwESELAAAAAExEyAIAAAAAExGyAAAAAMBEhCwAAAAAMBEhCwAAAABMRMgCAAAAABMRsgAAAADARIQsAAAAADARIQsAAAAATETIAgAAAAATEbIAAAAAwESELAAAAAAwESELAAAAAExEyAIAAAAAExGyAAAAAMBEhCwAAAAAMBEhCwAAAABMRMgCAAAAABMRsgAAAADARIQsAAAAADARIQsAAAAATETIAgAAAAATEbIAAAAAwESELAAAAAAwkVNuFwAAAADcMcOQwtZLn/8uXbomPekrfdZOeqxIxsvcTJHe2iAt/FOKuSKVdJf6+ktjGksWS/bXG5soDf5B+naf5GCROlaRPmktFXT5p82PB1PXs/uc5OokNS4rTWoplSt0L94NPCC4kgUAAIC868PN0tQt0sx20pbnJTdnqdV/pWvJGS8z4Vfps63S9LbSnlekCUGp65m2JWfr7blc2n1Wiugtre4hbTwqDfz2n/mHL0odvpKeKi/tfFH6sZd0PlF6don57wMeKIQsAAAA5E2GIU35LfUKVAc/qbqP9OUz0qnL0sq9GS8XeTy1ffC/Uq8odXpCallRij6Z/fXuOSetOSh98bQUUFpqWFaa1kZavEs6FZ/aZvsp6aYhvfuUVLGwVKuk9FqgtDNGSr55b98b5CpCFgAAAPKmwxdTu/sFVfhnmqdrauiJOpHxcoG+0tr/SfvPp/78R4z06zGpzWPZX2/UccnLVapT6p82QRVSuw1u+f9hrXbJ1J/n7Uztohh3TfrvH6nt8jne9e7jwcU9WQAAAMibYq6k/rd4Qdvpxd3+mWfPyIZSfJLkN11ydEgNQO81l3pWz/56Y65Ixdxs5zs5SoXz/9OmfCHpp+ekLkulF75NvarVoLT0fc+c7yvyFEIWAAAA8oZFf6aGlTTf3WFY+Xq3tOgvKbyj9ESx1O57Q9ekDoDRx9+UUiVJMZelAaukPjWk7tWky0nS2PVSp69T7+NKG2QDDx1CFgAAAPKGpx+XAm7pnpf0/+9rOnNFKuH+z/QzCZK/T8brGRGRejWrW7XUn6sVl45eksZvSg1ZPgWzXq9PQelsgu16b9yUYq/+s/yMrandDD9s+U+bhc9KvpOlLSek+r7Z3XPkMdyTBQAAgLzB3UWqVOSfVxXv1ECz9vA/beKvpQaYBqUzXk9icuq9UrdydJBSjNT/L18o6/U28E0d2n37qX/arDucuo60IJjRdqR/toWHEiELAAAAeZPFIg2tL727UVq1V/rrjNR7RWq3vxC/f9o1XyBNv2V49vb/kt7bKH23XzpyUVqxR/o4SnqmcvbXW9lbal0ptTtg9Alp8zFp0PdSt6pSSY/UNsGPSVtPSm9vkA5ckH4/JfVbKZX1lGqWuB/vEHJJnglZsbGx6tmzpzw8POTl5aXQ0FBduZLJDY2SYmJi9Nxzz8nHx0dubm6qVauWvvnmm/tUMQAAAO6515+UBtdLfT5V3dnSlevSml6Sa75/2hyKTX0+VZppbaVOVaSXv5Mqz5Be+0l6obb0TrOcrXfRs5JfUan5l1LbRVLDMtLs9v/Mf6pC6n1fK/dKNWdKrRdKLk6p68l/y3rw0LEYhpEnrlW2adNGp0+f1qxZs5ScnKx+/fqpbt26Cg8Pz3CZli1b6tKlS5o+fbqKFi2q8PBwhYWFadu2bapZs2a2thsfHy9PT0/FxcXJw8PDrN0BAACQJFk0LrdLAB54hsJyuwRJ2c8GeeJK1p49e7RmzRp98cUXCggIUMOGDTVt2jQtXrxYp06dynC5yMhIDR48WPXq1VOFChU0ZswYeXl5afv27fexegAAAACPkjwRsqKiouTl5aU6depYpwUFBcnBwUFbtmzJcLnAwEAtWbJEsbGxSklJ0eLFi3Xt2jU1bdo0w2WSkpIUHx9v8wIAAACA7MoTQ7jHxMSoWLFiNtOcnJxUuHBhxcTEZLjc119/ra5du6pIkSJycnJSgQIFtGLFClWqVCnDZcaPH69x47hsDwAA7o8HpRsUAPPk6pWskSNHymKxZPrau3fvHa//zTff1KVLl/Tzzz9r27ZtGjZsmLp06aK//vorw2VGjRqluLg46+v48eN3vH0AAAAAj55cvZI1fPhw9e3bN9M2FSpUkI+Pj86ePWsz/caNG4qNjZWPj/0HzR06dEjTp0/Xrl279MQTT0iSatSooU2bNmnGjBmaOXOm3eVcXFzk4uKS850BAAAAAOVyyPL29pa3t3eW7Ro0aKBLly5p+/btql27tiRp3bp1SklJUUBAgN1lEhNTh+l0cLC9WOfo6KiUlJS7rBwAAAAA7MsTA19UrlxZrVu31oABAxQdHa3Nmzdr0KBB6tatm0qWLClJOnnypPz8/BQdHS1J8vPzU6VKlfTCCy8oOjpahw4d0qRJkxQREaGQkJBc3BsAAAAAD7M8EbIkadGiRfLz81Pz5s3Vtm1bNWzYULNnz7bOT05O1r59+6xXsPLly6fvv/9e3t7eat++vapXr64vv/xSCxYsUNu2bXNrNwAAAAA85PLMw4hzCw8jBgAAACA9ZA8jBgAAAIC8gpAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgInyTMh67733FBgYqAIFCsjLyytbyxiGobFjx6pEiRLKnz+/goKCdODAgXtbKAAAAIBHWp4JWdevX1fnzp310ksvZXuZDz/8UFOnTtXMmTO1ZcsWubm5qVWrVrp27do9rBQAAADAo8xiGIaR20XkxPz58zV06FBdunQp03aGYahkyZIaPny4XnvtNUlSXFycihcvrvnz56tbt27Z2l58fLw8PT0VFxcnDw+Puy0fAAAAQB6V3WzgdB9ruq8OHz6smJgYBQUFWad5enoqICBAUVFRGYaspKQkJSUlWX+Oi4uTlPqGAgAAAHh0pWWCrK5TPbQhKyYmRpJUvHhxm+nFixe3zrNn/PjxGjduXLrpvr6+5hYIAAAAIE+6fPmyPD09M5yfqyFr5MiRmjBhQqZt9uzZIz8/v/tUkTRq1CgNGzbM+nNKSopiY2NVpEgRWSyW+1YH8ob4+Hj5+vrq+PHjdCcFHmIc68Cjg+MdmTEMQ5cvX1bJkiUzbZerIWv48OHq27dvpm0qVKhwR+v28fGRJJ05c0YlSpSwTj9z5oz8/f0zXM7FxUUuLi4207I7miEeXR4eHpyIgUcAxzrw6OB4R0Yyu4KVJldDlre3t7y9ve/JusuXLy8fHx+tXbvWGqri4+O1ZcuWHI1QCAAAAAA5kWeGcD927Jh27typY8eO6ebNm9q5c6d27typK1euWNv4+flpxYoVkiSLxaKhQ4fq3Xff1apVq/TXX3+pd+/eKlmypEJCQnJpLwAAAAA87PLMwBdjx47VggULrD/XrFlTkrR+/Xo1bdpUkrRv3z7raICS9PrrryshIUEDBw7UpUuX1LBhQ61Zs0aurq73tXY8vFxcXBQWFpauiymAhwvHOvDo4HiHGfLcc7IAAAAA4EGWZ7oLAgAAAEBeQMgCAAAAABMRsgAAAADARIQsAAAAADARIQv4//r27SuLxaIXX3wx3bxXXnlFFovF+vDsc+fO6aWXXlKZMmXk4uIiHx8ftWrVSps3b7YuU65cOVkslnSvDz744H7tEoAM5OR4TxMVFSVHR0cFBwenW+bIkSN2j3eLxaLffvvtXu0GgDuUdg6wWCzKly+fypcvr9dff13Xrl2TlHpMh4aGqnz58sqfP78qVqyosLAwXb9+PZcrR16RZ4ZwB+4HX19fLV68WJMnT1b+/PklSdeuXVN4eLjKlCljbdexY0ddv35dCxYsUIUKFXTmzBmtXbtWFy5csFnf22+/rQEDBthMc3d3v/c7AiBL2T3e08yZM0eDBw/WnDlzdOrUKZUsWTJdm59//llPPPGEzbQiRYrcmx0AcFdat26tefPmKTk5Wdu3b1efPn1ksVg0YcIE7d27VykpKZo1a5YqVaqkXbt2acCAAUpISNDEiRNzu3TkAYQs4Ba1atXSoUOHtHz5cvXs2VOStHz5cpUpU0bly5eXJF26dEmbNm3Shg0b1KRJE0lS2bJlVa9evXTrc3d3l4+Pz/3bAQDZlp3jPc2VK1e0ZMkSbdu2TTExMZo/f75Gjx6dbp1FihThmAfyiLSeKFLqly5BQUGKiIjQhAkT1Lp1a7Vu3dratkKFCtq3b58+++wzQhayhe6CwG369++vefPmWX+eO3eu+vXrZ/25YMGCKliwoFauXKmkpKTcKBGASbI63tN8/fXX8vPz0+OPP65evXpp7ty54jGTwMNj165dioyMlLOzc4Zt4uLiVLhw4ftYFfIyQhZwm169eunXX3/V0aNHdfToUW3evFm9evWyzndyctL8+fO1YMECeXl56cknn9To0aP1559/plvXf/7zH2soS3tt2rTpfu4OgExkdbynmTNnjnV669atFRcXp19++SVdu8DAwHTHPIAH0+rVq1WwYEG5urqqWrVqOnv2rEaMGGG37cGDBzVt2jS98MIL97lK5FV0FwRu4+3treDgYM2fP1+GYSg4OFhFixa1adOxY0cFBwdr06ZN+u233/TDDz/oww8/1BdffGFzs/yIESPS3TxfqlSp+7AXALIjO8f7vn37FB0drRUrVkhK/aKla9eumjNnjpo2bWrTdsmSJapcufL9Kh/AXWjWrJk+++wzJSQkaPLkyXJyclLHjh3TtTt58qRat26tzp07p7vPGsgIIQuwo3///ho0aJAkacaMGXbbuLq6qkWLFmrRooXefPNNPf/88woLC7MJVUWLFlWlSpXuR8kA7lBWx/ucOXN048YNm4EuDMOQi4uLpk+fLk9PT+t0X19fjnkgj3Bzc7Mer3PnzlWNGjU0Z84chYaGWtucOnVKzZo1U2BgoGbPnp1bpSIPorsgYEfr1q11/fp1JScnq1WrVtlapkqVKkpISLjHlQEwW2bH+40bN/Tll19q0qRJ2rlzp/X1xx9/qGTJkvrqq69yqWoAZnJwcNDo0aM1ZswYXb16VVLqFaymTZuqdu3amjdvnhwc+LMZ2ceVLMAOR0dH7dmzx/r/t7pw4YI6d+6s/v37q3r16nJ3d9e2bdv04YcfqkOHDjZtL1++rJiYGJtpBQoUkIeHx73dAQDZltnxvnr1al28eFGhoaE2V6yk1G7Dc+bMsXnW1oULF9Id815eXnJ1db1H1QMwS+fOnTVixAjNmDFD3bt3V9OmTVW2bFlNnDhR586ds7ZjBFFkByELyEBGQahgwYIKCAjQ5MmTdejQISUnJ8vX11cDBgxIN6Tz2LFjNXbsWJtpL7zwgmbOnHnP6gaQcxkd73PmzFFQUFC6gCWlhqwPP/xQf/75p3X5oKCgdO2++uordevWzdyCAZjOyclJgwYN0ocffqj8+fPr4MGDOnjwoEqXLm3TjpFFkR0Wg08KAAAAAJiGzqUAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJ/h8PPi+P+E2axwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the results \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap('winter')\n",
    "colors = cmap(np.linspace(0, 1, 3))\n",
    "#extract results\n",
    "results = {\n",
    "    'eval_mse': 0.01722853071987629,\n",
    "    'eval_mae': 0.08046024292707443,\n",
    "    'eval_r2': -0.8008329840570281\n",
    "}\n",
    "#plot\n",
    "metrics = ['MSE', 'MAE', 'R2']\n",
    "values = [results['eval_mse'], results['eval_mae'], results['eval_r2']]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "bars = plt.bar(metrics, values, color=[colors[0], colors[1], colors[2]])  \n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Hugging Face MSE, MAE, and R2 Metrics for Ukraine-Russia War')\n",
    "plt.ylabel('Values')\n",
    "plt.ylim(min(min(values) - 0.1, -1), max(values) + 0.1)  # Set y-limits to make R2 value clear\n",
    "\n",
    "# Adding data labels\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()  # Get the height of the bar (value of the metric)\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4),  # Position the text in the middle of the bar\n",
    "             verticalalignment='bottom' if yval < 0 else 'bottom',  # Adjust alignment for negative values\n",
    "             ha='center')  # Horizontal alignment is center\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ed946-4c35-4f56-821e-0ac4130f138b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7005f24-d09b-4bd5-8a08-71dccc8958a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
